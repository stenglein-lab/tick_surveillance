// TODO [possibly]: port to DSL2: https://github.com/stenglein-lab/tick_surveillance/issues/5
nextflow.enable.dsl=1

// first setup defaults for main directories
// these can be overridden if, e.g., testing
params {
  // --------------------------------
  // Directories for input and output
  // --------------------------------
  input_dir             = "input" 
  fastq_dir             = "${input_dir}/fastq/"
  outdir                = "./results"
  python_venv_path      = "${baseDir}/python_venv/"
}

// a test profile
profiles {
  test { 
    includeConfig 'conf/test.config'
  }
}

// params that include derivatives of main directories
params {

  // pattern to match for fastq files
  fastq_pattern         = "*_R[12]_*.fastq*"

  // Directory where R (and any other) scripts are.
  script_dir            = "${baseDir}/scripts"
  R_lib_dir             = "${baseDir}/lib/R/"

  initial_fastqc_dir    = "${outdir}/initial_fastqc/"
  post_trim_fastqc_dir  = "${outdir}/post_trim_fastqc/"
  trimmed_outdir        = "${outdir}/trimmed_fastq"
  dada_outdir           = "${outdir}/dada2"
  blast_outdir          = "${outdir}/blast"
  tree_outdir           = "${outdir}/trees"
  tracedir              = "${outdir}/pipeline_info"
  log_outdir            = "${outdir}/log"

  // prefix for pipeline output files: today's date.  
  // can override this (--output_file_prefix whatever) on command line
  output_prefix         = new java.util.Date().format( 'yyyy_MM_dd_')

  // -------------------
  // Reference sequences
  // -------------------
  refseq_dir            = "${baseDir}/refseq/" 
  refseq_fasta_dir      = "${outdir}/refseq_fasta/"
  targets               = "${params.refseq_dir}/targets.tsv"

  // ---------------
  // Sample metadata
  // ---------------
  // should force user to specify this value
  // metadata              = "${params.input_dir}/sample_metadata.xlsx"

  // -------------------------------
  // Columns in surveillance report
  // -------------------------------
  surveillance_columns  = "${params.refseq_dir}/surveillance_columns.txt"

  // ---------
  // Trimming 
  // ---------
  // the primers that will be trimmed off of the ends of amplicons
  primers               = "${params.refseq_dir}/primers.tsv"
  
  // shortest amplicon = tick Actin @ 196 bp
  post_trim_min_length  = "100" 

  // to trim Tru-seq style adapters need 10 bp of overlap
  // this to avoid false-positive trimming
  adapters_min_overlap  = 10

  // set allowable error rate for trimming of primer sequences on ends of amplicons
  // cutadapt default is 10% (0.1) - use 20% 
  amplicon_primers_max_error_fraction = 0.2

  // ----------
  // Testing 
  // ----------
  // These parameters will be overridden by settings in conf/test.config in test profile 
  use_simulated_test_dataset         = false
  simulated_fastq_dir                = null
  
  
  // ----------------------------------------------
  // Blast e-value cutoffs and other configuration
  // ----------------------------------------------
  max_blast_refseq_evalue = "1e-10"   // maximum e-value for blastn of ASVs against reference sequences 
  max_blast_nt_evalue     = "1e-10"   // maximum e-value for blastn of unassigned sequences against nt database
  blast_perc_identity     = "70"      // the value passed to -perc_identity in blastn of unassigned sequences
  blast_qcov_hsp_perc     = "70"      // the value passed to -qcov_hsp_perc in blastn of unassigned sequences

  // -------------------------------------------------------------------------------------
  // How many reads will be required to make call a positive hit for surveillance targets?
  // -------------------------------------------------------------------------------------
  min_reads_for_positive_surveillance_call = 50

  // ----------------------
  // Remote or local BLAST
  // ----------------------
  // turn off BLASTing of unassigned sequences by default
  // if this should be turned on, either override on the command-line
  // or setup blasting in a profile, as in profile stenglein below
  blast_unassigned_sequences = false
  
  // the path to a directory containing a local copy of the NCBI nt blast database
  local_nt_database_dir      = null
  // the name of the local copy of the NCBI nt blast database: nt by default
  local_nt_database_name     = "nt"

  // a directory containing a local copy of the blast taxonomy information
  // from: https://ftp.ncbi.nlm.nih.gov/blast/db/taxdb.tar.gz
  // if this is set to null, the pipeline will download a new copy in the 
  // working directory
  blast_tax_dir              = null

  // Should BLAST of unassigned sequences be remote (use -remote option)
  // This will cause blastn to run much slower but will not require
  // the installation of a local database.
  remote_blast_nt            = false

  // should we make phylogenetic trees?
  make_trees = true

  // turn this parameter on to pull docker containers and convert to singularity
  //
  // see e.g.: https://nf-co.re/gwas#quick-start, which states:
  //
  //   "If you are persistently observing issues downloading Singularity images directly 
  //    due to timeout or network issues then please use the --singularity_pull_docker_container 
  //    parameter to pull and convert the Docker image instead."
  //
  // TODO: this option is provided in nf-core pipelines but is it necessary?
  //       possibly remove this option and the corresponding if/else statment in processes?
  //
  singularity_pull_docker_container = false

  // Max resource allocation options
  // Defaults only, expecting to be overwritten
  max_memory                 = '64.GB'
  max_cpus                   = 16
  max_time                   = '120.h'
}

// include nf-core-style base.config, which defines 
// maximum resource limits for processes with different labels
includeConfig 'conf/base.config'

// control # of concurrent instances of processes 
process {

  withLabel: 'few_forks' {
    maxForks = 4
  }
  withLabel: 'many_forks' {
    maxForks = 16
  }
}


profiles {

  // profile for developing on Stenglein workstation
  stenglein {
    exector.name                      = 'local'
    executor.queueSize                = 32
    executor.cpus                     = 32
    executor.memory                   = '64 GB'
    params.blast_tax_dir              = "/home/databases/nt/"
    params.local_nt_database_dir      = "/home/databases/nt/"
    params.blast_unassigned_sequences = true
    params.remote_blast_nt            = false
  }

  // generic profile using remote blast
  remote_blast {
    params.local_nt_database_dir       = null
    params.blast_unassigned_sequences  = true
    params.remote_blast_nt             = true
  }

  // executor profile for CDC HPC environment
  sge { includeConfig './conf/sge.config' }
    
  // to run with an all-dependencies-in-one conda environment  
  // recommend running with singularity instead of conda
  conda {
    params.enable_conda    = true
    process.conda          = "$baseDir/conda/tick_conda_environment.yaml"
    conda.cacheDir         = "$HOME/conda_cacheDir"
    singularity.enabled    = false
  }

  // to run using singularity for software dependencies
  singularity {
    params.enable_conda    = false
    singularity.enabled    = true
    singularity.autoMounts = true
    singularity.cacheDir   = "$HOME/singularity_cacheDir"
  }
}

// some pipeline execution reports
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.pdf"
}

manifest {
    name            = 'stenglein-lab/tick_surveillance'
    author          = 'Mark Stenglein'
    homePage        = 'https://github.com/stenglein-lab/tick_surveillance'
    description     = 'A pipeline to analyze amplicon sequencing data for tick-borne pathogens'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.04.0'
    version         = '1.0.3'
    defaultBranch   = 'main' 
}

// Turn this cleanup option on to delete all intermediate files from the analysis
// see: https://www.nextflow.io/docs/latest/config.html
// cleanup = true


// Function to ensure that resource requirements don't go beyond
// a maximum limit
// From nf-core pipelines
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
