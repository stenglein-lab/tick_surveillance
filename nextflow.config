// first setup defaults for main directories
// these can be overridden if, e.g., testing
params {
  // --------------------------------
  // Directories for input and output
  // --------------------------------
  fastq_dir             = null
  outdir                = "results"

  // ---------------
  // Sample metadata
  // ---------------
  metadata              = null
}

// a test profile
profiles {
  test { 
    includeConfig 'conf/test.config'
  }
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// new params from DSL2 migration
params {

  // how should output files be published?  link = a hard link
  publish_dir_mode           = "link"

  // MultiQC options
  multiqc_config             = null
  multiqc_title              = null
  multiqc_logo               = null
  multiqc_methods_description = null

  monochrome_logs            = false
  validate_params            = true  // validate parameters according to schema in nextflow_schema.json
  validationLenientMode      = true  // see: https://nextflow-io.github.io/nf-validation/parameters/validation/#variable-type-checking
  show_hidden_params         = false
  schema_ignore_params       = ""


}

// params that include derivatives of main directories
params {

  // pattern to match for fastq files
  fastq_pattern         = "*_R[12]_*.fastq*"

  // Directory where python (and any other) scripts are.
  script_dir            = "${baseDir}/bin"

  // -----------------------------------------------
  // Directories to handle R and python dependencies
  // -----------------------------------------------

  // this directory contains R package tar.gz files
  R_tar_dir             = "${baseDir}/lib/R/"

  // the requirements.txt file (part of pipeline code)
  // that defines python modules and their versions
  python_requirements   = "${baseDir}/lib/requirements.txt"

  //  the name of a directory where a python venv will be created
  python_venv_path      = "python_venv"

  trimmed_outdir            = "${params.outdir}/trimmed_fastq"
  dada_outdir               = "${params.outdir}/dada2"
  blast_outdir              = "${params.outdir}/blast"
  tree_outdir               = "${params.outdir}/trees"
  QC_and_summary_stats_dir  = "${params.outdir}/QC_and_summary_stats"
  tracedir                  = "${params.QC_and_summary_stats_dir}/pipeline_info"
  log_outdir                = "${params.QC_and_summary_stats_dir}/log"
  fastqc_outdir             = "${params.QC_and_summary_stats_dir}/fastqc"
  cutadapt_trim_reports     = "${params.QC_and_summary_stats_dir}/cutadapt_trim_reports"
  multiQC_reports           = "${params.QC_and_summary_stats_dir}/multiqc"

  // prefix for pipeline output files: today's date.  
  // can override this (--output_file_prefix whatever) on command line
  output_prefix         = new java.util.Date().format( 'yyyy_MM_dd_')

  // -------------------
  // Reference sequences
  // -------------------
  refseq_dir            = "${baseDir}/refseq/" 
  targets               = "${params.refseq_dir}/targets.tsv"

  // -------------------
  // filter unassigned sequences
  // -------------------
  filter_unassigned_seq = "Borrelia,Borreliella,Babesia,Anaplasma,Ehrlichia"

  // -------------------------------
  // Columns in surveillance report
  // -------------------------------
  surveillance_columns  = "${params.refseq_dir}/surveillance_columns.txt"

  // ----------------------------------------------
  // Initial primer, adapter, and quality trimming 
  // ----------------------------------------------
  // the primers that will be trimmed off of the ends of amplicons
  primers               = "${params.refseq_dir}/primers.tsv"
  
  // shortest amplicon = tick Actin @ 196 bp
  post_trim_min_length  = 100 

  // to trim Tru-seq style adapters need 10 bp of overlap
  // this to avoid false-positive trimming
  adapters_min_overlap  = 10

  // set allowable error rate for trimming of primer sequences on ends of amplicons
  // cutadapt default is 10% (0.1) - use 20% 
  amplicon_primers_max_error_fraction = 0.2

  // lower basecall quality limits:
  // these values will be input to cutadapt (-q and -Q)
  // the first number is for trimming bases from the 5' end
  // the second number is for trimming bases from the 3' end
  // see: https://cutadapt.readthedocs.io/en/stable/guide.html#quality-trimming
  basecall_quality_limit  = "18,18"


  // ----------------------------------------------------------------
  // Dada2 options 
  // parameters named the same as the corresponding dada2 arguments
  // ----------------------------------------------------------------
  dada2_maxN         = 0
  dada2_maxEE        = 2   // --> "c(2,2)"
  dada2_truncQ       = 2
  dada2_trimRight    = 0
  dada2_min_reads    = 10  // minimum total # of reads in the whole dataset: if lower than this value, dada2 will discard dataset 
  dada2_min_overlap  = 12  // minimum length of the overlap required for merging the forward and reverse reads by dada2::mergePairs
  dada2_max_mismatch = 0   // maximum mismatches allowed in the overlap region of paired reads for dada2::mergePairs

  // ----------------------------------------------
  // Blast e-value cutoffs and other configuration
  // ----------------------------------------------
  max_blast_refseq_evalue = 1e-10   // maximum e-value for blastn of ASVs against reference sequences 
  max_blast_nt_evalue     = 1e-10   // maximum e-value for blastn of unassigned sequences against nt database
  blast_perc_identity     = 70      // the value passed to -perc_identity in blastn of unassigned sequences
  blast_qcov_hsp_perc     = 70      // the value passed to -qcov_hsp_perc in blastn of unassigned sequences

  // -------------------------------------------------------------------------------------
  // How many reads will be required to make call a positive hit for surveillance targets?
  // -------------------------------------------------------------------------------------
  min_reads_for_positive_surveillance_call = 50

  // ----------------------
  // Remote or local BLAST
  // ----------------------
  // turn off BLASTing of unassigned sequences by default
  // if this should be turned on, either override on the command-line
  // or setup blasting in a profile, as in profile stenglein below
  blast_unassigned_sequences = false
  
  // the path to a directory containing a local copy of the NCBI nt blast database
  local_nt_database_dir      = null
  // the name of the local copy of the NCBI nt blast database: nt by default
  local_nt_database_name     = "nt"

  // a directory containing a local copy of the blast taxonomy information
  // from: https://ftp.ncbi.nlm.nih.gov/blast/db/taxdb.tar.gz
  // if this is set to null, the pipeline will download a new copy in the 
  // working directory
  blast_tax_dir              = null

  // Should BLAST of unassigned sequences be remote (use -remote option)
  // This will cause blastn to run much slower but will not require
  // the installation of a local database.
  remote_blast_nt            = false

  // Restrict BLASTing of unassigned sequences to these taxids
  // this should be of the form of a comma-separated list of taxids
  // e.g. "766,1643685,6656,40674,5794"
  taxids_of_interest         = null

  // should we make phylogenetic trees?
  make_trees                 = true

  // turn this parameter on to pull docker containers and convert to singularity
  //
  // see e.g.: https://nf-co.re/gwas#quick-start, which states:
  //
  //   "If you are persistently observing issues downloading Singularity images directly 
  //    due to timeout or network issues then please use the --singularity_pull_docker_container 
  //    parameter to pull and convert the Docker image instead."
  //
  singularity_pull_docker_container = false

  // Max resource allocation options
  // Defaults only, expecting to be overwritten
  max_memory                 = '64.GB'
  max_cpus                   = 16
  max_time                   = '120.h'
}

// include nf-core-style base.config, which defines 
// maximum resource limits for processes with different labels
includeConfig 'conf/base.config'

// control # of concurrent instances of processes 
process {

  withLabel: 'few_forks' {
    maxForks = 4
  }
  withLabel: 'many_forks' {
    maxForks = 16
  }
}


profiles {

  // profile for developing on Stenglein workstation
  stenglein {
    email                             = "mark.stenglein@colostate.edu"
    email_on_fail                     = "mark.stenglein@colostate.edu"
    exector.name                      = 'local'
    executor.queueSize                = 32
    executor.cpus                     = 32
    executor.memory                   = '64 GB'
    params.blast_tax_dir              = "/home/databases/nt/"
    params.local_nt_database_dir      = "/home/databases/nt/"
    params.local_nt_database_name     = "nt"
    params.blast_unassigned_sequences = true
    params.remote_blast_nt            = false
  }

  // generic profile using remote blast
  remote_blast {
    params.local_nt_database_dir       = null
    params.blast_unassigned_sequences  = true
    params.remote_blast_nt             = true
  }

  // executor profile for CDC HPC environment
  sge { includeConfig './conf/sge.config' }
    
  // to run with an all-dependencies-in-one conda environment  
  // recommend running with singularity instead of conda
  conda {
    conda.enabled          = true
    conda.cacheDir         = "$HOME/conda_cacheDir"
    singularity.enabled    = false
  }

  // to run using singularity for software dependencies
  singularity {
    conda.enabled          = false
    singularity.enabled    = true
    singularity.autoMounts = true
    singularity.cacheDir   = "$HOME/singularity_cacheDir"
  }
}

// some pipeline execution reports
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.pdf"
}

manifest {
    name            = 'stenglein-lab/tick_surveillance'
    author          = 'Mark Stenglein'
    homePage        = 'https://github.com/stenglein-lab/tick_surveillance'
    description     = 'A pipeline to analyze amplicon sequencing data for tick-borne pathogens'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.10.0'
    version         = '2.0.0'
    defaultBranch   = 'main' 
}

// Turn this cleanup option on to delete all intermediate files from the analysis
// see: https://www.nextflow.io/docs/latest/config.html
cleanup = false


// Function to ensure that resource requirements don't go beyond
// a maximum limit
// From nf-core pipelines
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
